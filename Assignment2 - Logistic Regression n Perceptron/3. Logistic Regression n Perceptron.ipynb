{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3. Logistic Regression n Perceptron.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1oVjd__DS5Qxcxu-LYRfrnmwwQLG84gsQ",
      "authorship_tag": "ABX9TyMV9BMc7sCrKGtaVDvFCi1d"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfhZR6MmIFwg"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "CS6140 Assignment 2\n",
        "Question 3 - Logistic Regression and Perceptron\n",
        "Jun 3 2022\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split    #Library to split training and testing data"
      ],
      "metadata": {
        "id": "zHyqC_AGJa6E"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Read the dataset"
      ],
      "metadata": {
        "id": "5H0MmzNNJRsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(data_dir):\n",
        "    ''' data: input features\n",
        "        labels: output features\n",
        "    '''\n",
        "    dataset = pd.read_csv(data_dir)  \n",
        "    \n",
        "    features_names = dataset.columns.values[:-1]        #Equipvalent to feature_cols = ['feature1', 'feature2', 'feature3', 'feature4']\n",
        "    features_data = dataset[features_names] \n",
        "    labels_name = dataset.columns.values[-1]   \n",
        "    labels_data = dataset[labels_name]\n",
        "\n",
        "    return features_names, features_data, labels_name, labels_data\n",
        "    \n",
        "    #return features_names, labels_name"
      ],
      "metadata": {
        "id": "HhgFkJDKJTWc"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Part 1"
      ],
      "metadata": {
        "id": "yXoPgJiV4c7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    \"\"\"The sigmoid function.\"\"\"\n",
        "    return 1.0/(1.0+np.exp(-z))"
      ],
      "metadata": {
        "id": "4kWOy-A0SBoR"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Implement the loss function for logistic regression\n",
        "\n",
        "def compute_cost(ip, op, params):\n",
        "    \"\"\"\n",
        "    Cost function in linear regression where the cost is calculated\n",
        "    ip: input variables\n",
        "    op: output variables\n",
        "    params: corresponding parameters\n",
        "    Returns cost\n",
        "    \"\"\"\n",
        "   \n",
        "    num_of_samples = len(op)\n",
        "\n",
        "    y_hat = sigmoid(np.dot(ip, params))\n",
        "    nll = sum((-op * np.log(y_hat)) - ((1- op)*np.log(1-y_hat)))\n",
        "    cost = nll/num_of_samples\n",
        "    gradient = np.dot(ip.transpose(), (y_hat - op)) / num_of_samples\n",
        "\n",
        "#     print (cost_sum)\n",
        "    return nll, gradient\n",
        "    "
      ],
      "metadata": {
        "id": "ihOBcGt-VRxN"
      },
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Part 2"
      ],
      "metadata": {
        "id": "7z3hhHjS4hKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic_regression_using_batch_gradient_descent(ip, op, params, alpha, num_iter, batch_size = 1):\n",
        "    \"\"\"\n",
        "    Compute the params for logistic regression using batch gradient descent\n",
        "    ip: input variables\n",
        "    op: output variables\n",
        "    params: corresponding parameters\n",
        "    alpha: learning rate\n",
        "    max_iter: maximum number of iterations\n",
        "    Returns parameters, cost, params_store\n",
        "    \"\"\" \n",
        "    # initialize iteration, number of samples, cost and parameter array\n",
        "\n",
        "    \n",
        "    #batchify the data into mini-batches\n",
        "\n",
        "    \n",
        "    \n",
        "    # Compute the cost and store the params for the corresponding cost\n",
        "    cost_list = []\n",
        "    for i in range(num_iter):\n",
        "        cost, gradient = compute_cost(ip, op, params)\n",
        "        params = params - (alpha * gradient)\n",
        "        cost_list.append(cost)\n",
        "    \n",
        "    return params, cost_list"
      ],
      "metadata": {
        "id": "_MV9qHqY4WDi"
      },
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Version 1 : normalized data by z-score\n",
        "def featureNormalization_zscore(X):\n",
        "    \"\"\"\n",
        "    Take in numpy array of X values and return normalize X values,\n",
        "    the mean and standard deviation of each feature\n",
        "    \"\"\"\n",
        "    mean=np.mean(X,axis=0)\n",
        "    std=np.std(X,axis=0)\n",
        "    \n",
        "    X_norm = (X - mean)/std\n",
        "    \n",
        "    return X_norm , mean , std"
      ],
      "metadata": {
        "id": "iEJ6_M4O575S"
      },
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Version 2 : normalized data by min max normalization\n",
        "def featureNormalization_minmax(X):\n",
        "    \"\"\"\n",
        "    Take in numpy array of X values and return normalize X values,\n",
        "    the mean and standard deviation of each feature\n",
        "    \"\"\"\n",
        "    mean=np.mean(X,axis=0)\n",
        "    min=np.min(X, axis=0)\n",
        "    max=np.max(X, axis=0)\n",
        "    \n",
        "    X_norm = (X - min)/(max - min)\n",
        "    std = 0\n",
        "    \n",
        "    return X_norm , mean , std"
      ],
      "metadata": {
        "id": "1Mj5o7tztear"
      },
      "execution_count": 261,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Part 4"
      ],
      "metadata": {
        "id": "SJ8cwD4GfQvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "#reserve the test data, do not use them for cross-validation!\n",
        "\n",
        "DATA_DIR = \"/content/drive/My Drive/Colab Notebooks/CS6140 Assignment2/default of credit card clients2.csv\"\n",
        "features_names, features_data, labels_name, labels_data = load_data(DATA_DIR)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(features_data, labels_data, test_size=0.20) #x_train datatype <class 'pandas.core.frame.DataFrame'>\n",
        "\n",
        "np.set_printoptions(suppress=True)      #with np set to printoptions, the printout would not be in scientific e to the power of x format"
      ],
      "metadata": {
        "id": "EuLf-likKYtT"
      },
      "execution_count": 262,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sigmoid(0))\n",
        "\n",
        "num_of_features = x_train.shape[1]      #x_train.shape (3984, 25)\n",
        "x_train, x_train_mean, x_train_std = featureNormalization_minmax(x_train)\n",
        "x_train = np.append(np.ones((x_train.shape[0],1)), x_train, axis=1)       #x_train datatype <class 'numpy.ndarray'>, append bias with all ones at the end of dataset\n",
        "x_test = np.append(np.ones((x_test.shape[0],1)), x_test, axis=1)          #append bias with all ones at the end of dataset\n",
        "\n",
        "params = np.zeros((num_of_features+1,1))  #initialize params as 0 by rows as num of x_train columns, and 1 single column\n",
        "y_train = y_train.values.reshape(x_train.shape[0],1)\n",
        "\n",
        "#see sample of the learning for the first iteration\n",
        "#cost, grad = compute_cost(x_train, y_train, params)\n",
        "#print(\"Cost of initial theta is\",cost)\n",
        "\n",
        "#Run Gradient Descent\n",
        "alpha=1\n",
        "num_iters=400\n",
        "batch_size = 1\n",
        "params, cost = logistic_regression_using_batch_gradient_descent(x_train, y_train, params, alpha, num_iters, batch_size)\n",
        "print(\"params\", params)\n",
        "print(\"cost\", np.array([cost]).transpose())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ih0c9Ux6lF3q",
        "outputId": "162fd3bb-2961-4758-d54f-34c5852f146f"
      },
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n",
            "params [[-1.60219192]\n",
            " [ 0.03261684]\n",
            " [-0.72565137]\n",
            " [-0.0330851 ]\n",
            " [-0.21926212]\n",
            " [-0.76878066]\n",
            " [ 0.06623846]\n",
            " [ 2.50002949]\n",
            " [ 1.19271247]\n",
            " [ 0.71888464]\n",
            " [ 0.38299951]\n",
            " [ 0.44294129]\n",
            " [ 0.00963234]\n",
            " [-0.25577745]\n",
            " [-0.23908245]\n",
            " [-0.20534998]\n",
            " [-0.14322165]\n",
            " [-0.17821225]\n",
            " [-0.51373757]\n",
            " [-0.36088432]\n",
            " [-0.43876614]\n",
            " [-0.12014484]\n",
            " [-0.28684309]\n",
            " [-0.22246689]\n",
            " [-0.22528028]]\n",
            "cost [[[2761.49836735]\n",
            "  [2266.56449849]\n",
            "  [2168.13841948]\n",
            "  [2140.93470208]\n",
            "  [2130.90118915]\n",
            "  [2125.82523995]\n",
            "  [2122.34232123]\n",
            "  [2119.41970468]\n",
            "  [2116.72042441]\n",
            "  [2114.13033676]\n",
            "  [2111.60962955]\n",
            "  [2109.14387989]\n",
            "  [2106.72745799]\n",
            "  [2104.35780682]\n",
            "  [2102.03345244]\n",
            "  [2099.75330903]\n",
            "  [2097.51643575]\n",
            "  [2095.32195177]\n",
            "  [2093.16900657]\n",
            "  [2091.05676968]\n",
            "  [2088.9844269 ]\n",
            "  [2086.95117905]\n",
            "  [2084.95624133]\n",
            "  [2082.998843  ]\n",
            "  [2081.07822716]\n",
            "  [2079.19365056]\n",
            "  [2077.34438335]\n",
            "  [2075.52970893]\n",
            "  [2073.74892375]\n",
            "  [2072.00133711]\n",
            "  [2070.28627102]\n",
            "  [2068.60305997]\n",
            "  [2066.9510508 ]\n",
            "  [2065.32960253]\n",
            "  [2063.73808614]\n",
            "  [2062.1758845 ]\n",
            "  [2060.64239213]\n",
            "  [2059.13701505]\n",
            "  [2057.65917066]\n",
            "  [2056.20828757]\n",
            "  [2054.7838054 ]\n",
            "  [2053.38517469]\n",
            "  [2052.0118567 ]\n",
            "  [2050.66332328]\n",
            "  [2049.33905672]\n",
            "  [2048.03854955]\n",
            "  [2046.76130445]\n",
            "  [2045.50683408]\n",
            "  [2044.27466089]\n",
            "  [2043.06431704]\n",
            "  [2041.87534416]\n",
            "  [2040.70729329]\n",
            "  [2039.55972466]\n",
            "  [2038.43220759]\n",
            "  [2037.3243203 ]\n",
            "  [2036.23564979]\n",
            "  [2035.16579168]\n",
            "  [2034.11435007]\n",
            "  [2033.08093738]\n",
            "  [2032.06517423]\n",
            "  [2031.06668925]\n",
            "  [2030.085119  ]\n",
            "  [2029.12010775]\n",
            "  [2028.17130742]\n",
            "  [2027.23837737]\n",
            "  [2026.32098431]\n",
            "  [2025.41880212]\n",
            "  [2024.53151175]\n",
            "  [2023.65880105]\n",
            "  [2022.80036468]\n",
            "  [2021.95590392]\n",
            "  [2021.1251266 ]\n",
            "  [2020.30774691]\n",
            "  [2019.50348533]\n",
            "  [2018.71206844]\n",
            "  [2017.93322886]\n",
            "  [2017.16670508]\n",
            "  [2016.41224136]\n",
            "  [2015.66958761]\n",
            "  [2014.93849926]\n",
            "  [2014.21873714]\n",
            "  [2013.5100674 ]\n",
            "  [2012.81226135]\n",
            "  [2012.12509539]\n",
            "  [2011.44835087]\n",
            "  [2010.781814  ]\n",
            "  [2010.12527575]\n",
            "  [2009.47853173]\n",
            "  [2008.84138209]\n",
            "  [2008.21363143]\n",
            "  [2007.59508871]\n",
            "  [2006.98556712]\n",
            "  [2006.38488402]\n",
            "  [2005.79286082]\n",
            "  [2005.20932294]\n",
            "  [2004.63409964]\n",
            "  [2004.067024  ]\n",
            "  [2003.50793282]\n",
            "  [2002.95666651]\n",
            "  [2002.41306903]\n",
            "  [2001.87698781]\n",
            "  [2001.34827367]\n",
            "  [2000.82678073]\n",
            "  [2000.31236635]\n",
            "  [1999.80489105]\n",
            "  [1999.30421844]\n",
            "  [1998.81021514]\n",
            "  [1998.32275073]\n",
            "  [1997.84169766]\n",
            "  [1997.3669312 ]\n",
            "  [1996.89832937]\n",
            "  [1996.43577286]\n",
            "  [1995.97914501]\n",
            "  [1995.52833171]\n",
            "  [1995.08322136]\n",
            "  [1994.64370479]\n",
            "  [1994.20967525]\n",
            "  [1993.78102831]\n",
            "  [1993.35766181]\n",
            "  [1992.93947583]\n",
            "  [1992.52637263]\n",
            "  [1992.11825659]\n",
            "  [1991.71503418]\n",
            "  [1991.31661388]\n",
            "  [1990.92290617]\n",
            "  [1990.53382346]\n",
            "  [1990.14928006]\n",
            "  [1989.7691921 ]\n",
            "  [1989.39347756]\n",
            "  [1989.02205614]\n",
            "  [1988.65484931]\n",
            "  [1988.29178018]\n",
            "  [1987.93277354]\n",
            "  [1987.57775577]\n",
            "  [1987.22665481]\n",
            "  [1986.87940016]\n",
            "  [1986.5359228 ]\n",
            "  [1986.19615519]\n",
            "  [1985.8600312 ]\n",
            "  [1985.52748613]\n",
            "  [1985.19845661]\n",
            "  [1984.87288063]\n",
            "  [1984.55069748]\n",
            "  [1984.23184772]\n",
            "  [1983.91627317]\n",
            "  [1983.60391684]\n",
            "  [1983.29472296]\n",
            "  [1982.9886369 ]\n",
            "  [1982.68560519]\n",
            "  [1982.38557544]\n",
            "  [1982.08849638]\n",
            "  [1981.79431778]\n",
            "  [1981.50299045]\n",
            "  [1981.21446622]\n",
            "  [1980.9286979 ]\n",
            "  [1980.64563928]\n",
            "  [1980.36524509]\n",
            "  [1980.08747099]\n",
            "  [1979.81227355]\n",
            "  [1979.53961022]\n",
            "  [1979.2694393 ]\n",
            "  [1979.00171997]\n",
            "  [1978.7364122 ]\n",
            "  [1978.4734768 ]\n",
            "  [1978.21287534]\n",
            "  [1977.95457019]\n",
            "  [1977.69852447]\n",
            "  [1977.44470203]\n",
            "  [1977.19306745]\n",
            "  [1976.94358601]\n",
            "  [1976.69622369]\n",
            "  [1976.45094715]\n",
            "  [1976.20772369]\n",
            "  [1975.96652129]\n",
            "  [1975.72730854]\n",
            "  [1975.49005465]\n",
            "  [1975.25472944]\n",
            "  [1975.02130332]\n",
            "  [1974.78974729]\n",
            "  [1974.56003291]\n",
            "  [1974.33213228]\n",
            "  [1974.10601807]\n",
            "  [1973.88166346]\n",
            "  [1973.65904216]\n",
            "  [1973.43812838]\n",
            "  [1973.21889685]\n",
            "  [1973.00132275]\n",
            "  [1972.78538176]\n",
            "  [1972.57105004]\n",
            "  [1972.35830417]\n",
            "  [1972.1471212 ]\n",
            "  [1971.93747861]\n",
            "  [1971.72935432]\n",
            "  [1971.52272665]\n",
            "  [1971.31757434]\n",
            "  [1971.11387653]\n",
            "  [1970.91161276]\n",
            "  [1970.71076293]\n",
            "  [1970.51130735]\n",
            "  [1970.31322668]\n",
            "  [1970.11650193]\n",
            "  [1969.92111449]\n",
            "  [1969.72704607]\n",
            "  [1969.53427874]\n",
            "  [1969.34279489]\n",
            "  [1969.15257723]\n",
            "  [1968.9636088 ]\n",
            "  [1968.77587295]\n",
            "  [1968.58935331]\n",
            "  [1968.40403385]\n",
            "  [1968.21989881]\n",
            "  [1968.03693271]\n",
            "  [1967.85512036]\n",
            "  [1967.67444685]\n",
            "  [1967.49489752]\n",
            "  [1967.316458  ]\n",
            "  [1967.13911415]\n",
            "  [1966.96285211]\n",
            "  [1966.78765825]\n",
            "  [1966.61351919]\n",
            "  [1966.44042178]\n",
            "  [1966.26835312]\n",
            "  [1966.09730052]\n",
            "  [1965.92725152]\n",
            "  [1965.75819388]\n",
            "  [1965.59011558]\n",
            "  [1965.4230048 ]\n",
            "  [1965.25684994]\n",
            "  [1965.0916396 ]\n",
            "  [1964.92736255]\n",
            "  [1964.7640078 ]\n",
            "  [1964.60156451]\n",
            "  [1964.44002205]\n",
            "  [1964.27936997]\n",
            "  [1964.11959799]\n",
            "  [1963.96069601]\n",
            "  [1963.80265412]\n",
            "  [1963.64546254]\n",
            "  [1963.48911169]\n",
            "  [1963.33359213]\n",
            "  [1963.17889461]\n",
            "  [1963.02500999]\n",
            "  [1962.87192933]\n",
            "  [1962.7196438 ]\n",
            "  [1962.56814475]\n",
            "  [1962.41742364]\n",
            "  [1962.26747211]\n",
            "  [1962.11828191]\n",
            "  [1961.96984493]\n",
            "  [1961.82215321]\n",
            "  [1961.6751989 ]\n",
            "  [1961.52897429]\n",
            "  [1961.38347178]\n",
            "  [1961.23868393]\n",
            "  [1961.09460338]\n",
            "  [1960.95122291]\n",
            "  [1960.8085354 ]\n",
            "  [1960.66653388]\n",
            "  [1960.52521145]\n",
            "  [1960.38456134]\n",
            "  [1960.24457689]\n",
            "  [1960.10525154]\n",
            "  [1959.96657883]\n",
            "  [1959.82855241]\n",
            "  [1959.69116603]\n",
            "  [1959.55441353]\n",
            "  [1959.41828884]\n",
            "  [1959.28278602]\n",
            "  [1959.14789917]\n",
            "  [1959.01362253]\n",
            "  [1958.87995039]\n",
            "  [1958.74687716]\n",
            "  [1958.61439731]\n",
            "  [1958.4825054 ]\n",
            "  [1958.35119609]\n",
            "  [1958.22046411]\n",
            "  [1958.09030425]\n",
            "  [1957.96071141]\n",
            "  [1957.83168055]\n",
            "  [1957.7032067 ]\n",
            "  [1957.57528499]\n",
            "  [1957.44791059]\n",
            "  [1957.32107875]\n",
            "  [1957.19478482]\n",
            "  [1957.06902417]\n",
            "  [1956.94379228]\n",
            "  [1956.81908467]\n",
            "  [1956.69489692]\n",
            "  [1956.57122471]\n",
            "  [1956.44806375]\n",
            "  [1956.32540982]\n",
            "  [1956.20325876]\n",
            "  [1956.08160647]\n",
            "  [1955.96044891]\n",
            "  [1955.83978211]\n",
            "  [1955.71960212]\n",
            "  [1955.59990508]\n",
            "  [1955.48068716]\n",
            "  [1955.36194462]\n",
            "  [1955.24367372]\n",
            "  [1955.12587082]\n",
            "  [1955.00853229]\n",
            "  [1954.89165459]\n",
            "  [1954.77523419]\n",
            "  [1954.65926763]\n",
            "  [1954.54375149]\n",
            "  [1954.42868241]\n",
            "  [1954.31405705]\n",
            "  [1954.19987214]\n",
            "  [1954.08612443]\n",
            "  [1953.97281074]\n",
            "  [1953.85992791]\n",
            "  [1953.74747282]\n",
            "  [1953.63544241]\n",
            "  [1953.52383365]\n",
            "  [1953.41264355]\n",
            "  [1953.30186916]\n",
            "  [1953.19150756]\n",
            "  [1953.08155587]\n",
            "  [1952.97201126]\n",
            "  [1952.86287092]\n",
            "  [1952.7541321 ]\n",
            "  [1952.64579204]\n",
            "  [1952.53784806]\n",
            "  [1952.43029749]\n",
            "  [1952.32313769]\n",
            "  [1952.21636608]\n",
            "  [1952.10998008]\n",
            "  [1952.00397716]\n",
            "  [1951.89835481]\n",
            "  [1951.79311056]\n",
            "  [1951.68824197]\n",
            "  [1951.58374663]\n",
            "  [1951.47962214]\n",
            "  [1951.37586615]\n",
            "  [1951.27247633]\n",
            "  [1951.16945039]\n",
            "  [1951.06678604]\n",
            "  [1950.96448104]\n",
            "  [1950.86253318]\n",
            "  [1950.76094024]\n",
            "  [1950.65970008]\n",
            "  [1950.55881053]\n",
            "  [1950.45826949]\n",
            "  [1950.35807485]\n",
            "  [1950.25822454]\n",
            "  [1950.15871651]\n",
            "  [1950.05954875]\n",
            "  [1949.96071924]\n",
            "  [1949.862226  ]\n",
            "  [1949.76406708]\n",
            "  [1949.66624053]\n",
            "  [1949.56874445]\n",
            "  [1949.47157694]\n",
            "  [1949.37473612]\n",
            "  [1949.27822014]\n",
            "  [1949.18202716]\n",
            "  [1949.08615537]\n",
            "  [1948.99060298]\n",
            "  [1948.8953682 ]\n",
            "  [1948.80044929]\n",
            "  [1948.70584449]\n",
            "  [1948.61155209]\n",
            "  [1948.5175704 ]\n",
            "  [1948.42389771]\n",
            "  [1948.33053236]\n",
            "  [1948.2374727 ]\n",
            "  [1948.1447171 ]\n",
            "  [1948.05226394]\n",
            "  [1947.96011162]\n",
            "  [1947.86825854]\n",
            "  [1947.77670315]\n",
            "  [1947.68544388]\n",
            "  [1947.5944792 ]\n",
            "  [1947.50380758]\n",
            "  [1947.41342751]\n",
            "  [1947.3233375 ]\n",
            "  [1947.23353607]\n",
            "  [1947.14402175]\n",
            "  [1947.05479309]\n",
            "  [1946.96584865]\n",
            "  [1946.87718701]\n",
            "  [1946.78880676]\n",
            "  [1946.70070649]\n",
            "  [1946.61288482]\n",
            "  [1946.52534038]\n",
            "  [1946.43807182]\n",
            "  [1946.35107777]\n",
            "  [1946.26435691]\n",
            "  [1946.17790791]\n",
            "  [1946.09172947]\n",
            "  [1946.00582027]\n",
            "  [1945.92017905]\n",
            "  [1945.83480451]\n",
            "  [1945.74969539]\n",
            "  [1945.66485044]\n",
            "  [1945.58026842]\n",
            "  [1945.49594808]\n",
            "  [1945.41188822]\n",
            "  [1945.32808762]]]\n"
          ]
        }
      ]
    }
  ]
}
