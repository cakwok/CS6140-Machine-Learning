{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3. Logistic Regression n Perceptron.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1oVjd__DS5Qxcxu-LYRfrnmwwQLG84gsQ",
      "authorship_tag": "ABX9TyPt1syOkaHRJkglCyrBbh/v"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1193,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LfhZR6MmIFwg",
        "outputId": "233dc62c-ee10-4b39-895d-6c365e4598e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nCS6140 Assignment 2\\nQuestion 3 - Logistic Regression and Perceptron\\nJun 3 2022\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1193
        }
      ],
      "source": [
        "\"\"\"\n",
        "CS6140 Assignment 2\n",
        "Question 3 - Logistic Regression and Perceptron\n",
        "Wing Man, Kwok\n",
        "Jun 3 2022\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split    #Library to split training and testing data\n",
        "from sklearn.metrics import classification_report       #Library to compute accuracy, precison and recall"
      ],
      "metadata": {
        "id": "zHyqC_AGJa6E"
      },
      "execution_count": 1194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the dataset\n",
        "def load_data(data_dir):\n",
        "  ''' features_names: input features names\n",
        "      features_data: input features\n",
        "      features_names: output features names\n",
        "      features_labels: output features\n",
        "  '''\n",
        "  dataset = pd.read_csv(data_dir)  \n",
        "\n",
        "  features_names = dataset.columns.values[:-1]        #Equipvalent to feature_cols = ['feature1', 'feature2', 'feature3', 'feature4']\n",
        "  features_data = dataset[features_names] \n",
        "  labels_names = dataset.columns.values[-1]   \n",
        "  labels_data = dataset[labels_names]\n",
        "\n",
        "  return features_names, features_data, labels_names, labels_data"
      ],
      "metadata": {
        "id": "HhgFkJDKJTWc"
      },
      "execution_count": 1195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 1 - Implementation of sigmoid function\n",
        "def sigmoid(z):\n",
        "  \"\"\"The sigmoid function.\"\"\"\n",
        "  sigmoid = 1.0/(1.0+np.exp(-z))\n",
        "  sigmoid = np.minimum(sigmoid, 0.9999)  # Set upper bound\n",
        "  sigmoid = np.maximum(sigmoid, 0.0001)  # Set lower bound\n",
        "  return sigmoid"
      ],
      "metadata": {
        "id": "4kWOy-A0SBoR"
      },
      "execution_count": 1196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementation of cost function\n",
        "def compute_cost(ip, op, params):\n",
        "  \"\"\"\n",
        "  Cost function in linear regression where the cost is calculated\n",
        "  ip: input variables\n",
        "  op: output variables\n",
        "  params: corresponding parameters\n",
        "  nll : negative log likelihood\n",
        "  y_hat : y hat\n",
        "  gradient : gradient\n",
        "  Returns cost, gradient\n",
        "  \"\"\"\n",
        "  \n",
        "  num_of_samples = len(op)\n",
        "\n",
        "  y_hat = sigmoid(np.dot(ip, params))\n",
        "  nll = sum((-op * np.log(y_hat)) - ((1- op)*np.log(1-y_hat)))  \n",
        "  cost = nll\n",
        "  gradient = np.dot(ip.transpose(), (y_hat - op))  \n",
        "\n",
        "  return cost, gradient"
      ],
      "metadata": {
        "id": "ihOBcGt-VRxN"
      },
      "execution_count": 1197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Part 2 - Implement logistic regression using batch gradient descent and evaluation \n",
        "def logistic_regression_using_batch_gradient_descent(ip, op, params, alpha, num_iter, batch_size = 1):\n",
        "  \"\"\"\n",
        "  Compute the params for logistic regression using batch gradient descent\n",
        "  ip: input variables\n",
        "  op: output variables\n",
        "  params: corresponding parameters\n",
        "  alpha: learning rate\n",
        "  num_iter: number of iterations\n",
        "  cost, cost_list: error function, error function in list format\n",
        "  gradient: gradient\n",
        "  Returns parameters, cost\n",
        "  \"\"\" \n",
        "  # initialize iteration, number of samples, cost and parameter array\n",
        "  cost_list = []\n",
        "  \n",
        "  #batchify the data into mini-batches\n",
        "  pass\n",
        "  \n",
        "  # Compute the cost and store the params for the corresponding cost\n",
        "  for i in range(num_iter):\n",
        "      cost, gradient = compute_cost(ip, op, params)\n",
        "      params = params - (alpha * gradient)\n",
        "      cost_list.append(cost)\n",
        "\n",
        "  return params, cost_list"
      ],
      "metadata": {
        "id": "_MV9qHqY4WDi"
      },
      "execution_count": 1198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data preparation Version 1 : normalize data by z-score\n",
        "def Normalize_zscore(X):\n",
        "  mean = np.mean(X,axis=0)\n",
        "  std = np.std(X,axis=0)\n",
        "  X_norm = (X - mean)/std\n",
        "  \n",
        "  return X_norm "
      ],
      "metadata": {
        "id": "iEJ6_M4O575S"
      },
      "execution_count": 1199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data preparation Version 2 : normalize data by min max normalization\n",
        "def Normalize_minmax(X):\n",
        "  min = np.min(X, axis=0)\n",
        "  max = np.max(X, axis=0)\n",
        "  X_norm = (X - min)/(max - min)\n",
        "  \n",
        "  return X_norm"
      ],
      "metadata": {
        "id": "1Mj5o7tztear"
      },
      "execution_count": 1200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Logistic Regression predictor\n",
        "def Predict(theta,X):\n",
        "    predictions = X.dot(theta)\n",
        "\n",
        "    return np.where(predictions >= 0.5, 1, 0)"
      ],
      "metadata": {
        "id": "GiP19ZGY0j_y"
      },
      "execution_count": 1201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Part 3 - Implementation of perceptron\n",
        "class Perceptron:\n",
        "  # constructor \n",
        "  def __init__ (self, num_of_x_features, alpha):\n",
        "    #self.weight = np.random.randn(num_of_x_features + 1) / np.sqrt(num_of_x_features)\n",
        "    self.weight = np.zeros((num_of_features+1))\n",
        "    self.b = None\n",
        "    self.alpha = alpha\n",
        "\n",
        "  # model\n",
        "  def classify(self, x):\n",
        "    return 1 if x > 0 else 0\n",
        "\n",
        "  # fitting the model by batch gradient decent\n",
        "  def fit(self, X, Y, epochs): \n",
        "    gradient = 0\n",
        "    for epoch in range(epochs):\n",
        "      for (x, y) in zip(X, Y):\n",
        "        y_hat = self.classify(np.dot(x, self.weight))\n",
        "        if y_hat != y:\n",
        "          gradient += (y - y_hat) * x\n",
        "      self.weight = self.weight + self.alpha * gradient\n",
        "\n",
        "  \"\"\"\n",
        "  # fitting the model by SGD\n",
        "  def fit(self, X, y, epochs): \n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      #gradient = 0\n",
        "      for (x, y) in zip(X, Y):\n",
        "        y_hat = self.classify(np.dot(x, self.weight))\n",
        "        if y_hat != y:\n",
        "          gradient = y - y_hat\n",
        "          self.weight = self.weight + self.alpha * gradient * x\n",
        "  \"\"\"\n",
        " \n",
        "  # predictor to predict on the data based on weight\n",
        "  def predict(self, X):\n",
        "    return self.classify(np.dot(X, self.weight))"
      ],
      "metadata": {
        "id": "2eWmI2EWpnaw"
      },
      "execution_count": 1202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Part 4 - Evaluate regression performance\n",
        "def evaluate(y_test, y_predict):\n",
        "  '''return the accuracy scores'''\n",
        "  \n",
        "  #compute accuracy\n",
        "  y_test_array = y_test.to_numpy()    #convert dataframe to numpy array\n",
        "  y_predict = y_predict.transpose()\n",
        "  total_num_samples = y_test.shape[0]\n",
        "\n",
        "  matches_count = np.count_nonzero(y_test_array == y_predict)   #return 1 to np.count, if y_true == y_predict, then count matches\n",
        "  accuracy = matches_count/total_num_samples\n",
        "\n",
        "  #compute precision\n",
        "  true_positive = np.sum((y_test_array == 1) & (y_predict == 1))\n",
        "  false_positive = np.sum((y_test_array == 0) & (y_predict == 1))\n",
        "  false_negative = np.sum((y_test_array == 1) & (y_predict == 0))\n",
        "  true_negative = np.sum((y_test_array == 0) & (y_predict == 0))\n",
        "  precision = true_positive/(true_positive + false_positive)\n",
        "\n",
        "  confusion_matrix = pd.DataFrame({\"Negative\":[true_negative, false_negative], \"Positive\":[false_positive, true_positive]}, index=['Negative', 'Positive'])\n",
        "  print(\"\\nConfusion Matrix\")\n",
        "  print(\"----------------------------------------------------\\n\" + \"\\t\\t\\tPredicted\")\n",
        "  print(\"Actual\", confusion_matrix, \"\\n\")\n",
        "  print(\"matches:\", matches_count, \"total number of samples:\", total_num_samples)\n",
        "  \n",
        "  #compute recall\n",
        "  recall = true_positive/(true_positive + false_negative)\n",
        "\n",
        "  #put computation result into dataframe\n",
        "  performance_matrix = pd.DataFrame({\"accuracy\":[accuracy], \"precision\":[precision], \"recall\":[recall], \"total number of samples\":[total_num_samples]})\n",
        "  print(\"\\nLogistic Regression Performance\")\n",
        "  print(\"---------------------------------------------------\")\n",
        "  print(performance_matrix.to_string(index=False), \"\\n\")\n",
        "\n",
        "  return"
      ],
      "metadata": {
        "id": "M13cb8KJIugk"
      },
      "execution_count": 1203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train the model\n",
        "#reserve the test data, do not use them for cross-validation!\n",
        "\n",
        "#load data\n",
        "DATA_DIR = \"/content/drive/My Drive/Colab Notebooks/CS6140 Assignment2/default of credit card clients2.csv\"\n",
        "features_names, features_data, labels_name, labels_data = load_data(DATA_DIR)\n",
        "\n",
        "#split data\n",
        "x_train, x_test, y_train, y_test = train_test_split(features_data, labels_data, test_size=0.2, random_state = 42) #x_train datatype <class 'pandas.core.frame.DataFrame'>\n",
        "\n",
        "#setup numpy print environment\n",
        "np.set_printoptions(suppress=True)      #with np set to printoptions, the printout would not be in scientific e to the power of x format\n",
        "#np.set_printoptions(threshold=np.inf)"
      ],
      "metadata": {
        "id": "EuLf-likKYtT"
      },
      "execution_count": 1204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "#compare results with sklearn logistic regression, raw, logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score \n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "x_train_numpy = x_train.to_numpy()\n",
        "y_train_numpy = y_train.to_numpy()\n",
        "x_test_numpy = x_test.to_numpy()\n",
        "y_test_numpy = y_test.to_numpy()\n",
        "\n",
        "clf = LogisticRegression(class_weight = 'balanced')\n",
        "clf.fit(x_train_numpy, y_train_numpy)\n",
        "y_pred = clf.predict(x_test_numpy)\n",
        "print(\"y_pred\", y_pred)\n",
        "print(accuracy_score(y_pred, y_test_numpy))\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "7lkwW4RMTIqv",
        "outputId": "c5708ea9-01c6-43bd-95cb-46bf7d3966cf"
      },
      "execution_count": 1205,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#compare results with sklearn logistic regression, raw, logistic regression\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import confusion_matrix, accuracy_score \\nfrom sklearn.pipeline import make_pipeline\\n\\nx_train_numpy = x_train.to_numpy()\\ny_train_numpy = y_train.to_numpy()\\nx_test_numpy = x_test.to_numpy()\\ny_test_numpy = y_test.to_numpy()\\n\\nclf = LogisticRegression(class_weight = \\'balanced\\')\\nclf.fit(x_train_numpy, y_train_numpy)\\ny_pred = clf.predict(x_test_numpy)\\nprint(\"y_pred\", y_pred)\\nprint(accuracy_score(y_pred, y_test_numpy))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1205
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predict by logistic regression - normalized data\n",
        "num_of_features = x_train.shape[1]      #x_train.shape (3984, 25)\n",
        "\n",
        "#normalize data\n",
        "x_train_minmax_normalized = Normalize_minmax(x_train)\n",
        "x_test_minmax_normalized = Normalize_minmax(x_test)\n",
        "\n",
        "#add bias column\n",
        "x_train_minmax_normalized = np.append(np.ones((x_train_minmax_normalized.shape[0],1)), x_train_minmax_normalized, axis=1)       #x_train datatype <class 'numpy.ndarray'>, append bias with all ones at the end of dataset\n",
        "x_test_minmax_normalized = np.append(np.ones((x_test_minmax_normalized.shape[0],1)), x_test_minmax_normalized, axis=1)          #x_train datatype <class 'numpy.ndarray'>, append bias with all ones at the end of dataset\n",
        "\n",
        "#reshape true label for calculation\n",
        "y_train_reshaped = y_train.values.reshape(x_train.shape[0],1)\n",
        "y_test_reshaped = y_test.values.reshape(x_test.shape[0],1)\n",
        "\n",
        "#Initialize parameters\n",
        "alpha=1\n",
        "num_iters = 200\n",
        "batch_size = 1\n",
        "params = np.zeros((num_of_features+1,1))      #initialize params as 0, by rows as num of x_train columns, and 1 single column\n",
        "\n",
        "#train the model by batch gradient decent\n",
        "params, cost = logistic_regression_using_batch_gradient_descent(x_train_minmax_normalized, y_train_reshaped, params, alpha, num_iters, batch_size)\n",
        "\n",
        "#test the model, get prediction\n",
        "y_predict = Predict(params, x_test_minmax_normalized)   #has to transpose y_predict for y_test for element wise comparison\n",
        "#print(\"prediction\", y_predict.transpose() )\n",
        "#print(\"y_test\", y_test.to_numpy())\n",
        "\n",
        "#compute accuracy of the model\n",
        "print(\"Logistic Regression - MinMax Normalized\")\n",
        "evaluate(y_test, y_predict)\n",
        "print(\"\\nTo compare with sklearn classification_report\")\n",
        "print(\"--------------------------------------------\")\n",
        "print(classification_report(y_test, y_predict))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ih0c9Ux6lF3q",
        "outputId": "43e6e729-b0b0-45cc-93ae-b144b21987ed"
      },
      "execution_count": 1206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: overflow encountered in exp\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression - MinMax Normalized\n",
            "\n",
            "Confusion Matrix\n",
            "----------------------------------------------------\n",
            "\t\t\tPredicted\n",
            "Actual           Negative  Positive\n",
            "Negative       681        90\n",
            "Positive       135        90 \n",
            "\n",
            "matches: 771 total number of samples: 996\n",
            "\n",
            "Logistic Regression Performance\n",
            "---------------------------------------------------\n",
            " accuracy  precision  recall  total number of samples\n",
            " 0.774096        0.5     0.4                      996 \n",
            "\n",
            "\n",
            "To compare with sklearn classification_report\n",
            "--------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.86       771\n",
            "           1       0.50      0.40      0.44       225\n",
            "\n",
            "    accuracy                           0.77       996\n",
            "   macro avg       0.67      0.64      0.65       996\n",
            "weighted avg       0.76      0.77      0.76       996\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predict by logistic regression - raw data\n",
        "\n",
        "#add bias column\n",
        "x_test = np.append(np.ones((x_test.shape[0],1)), x_test, axis=1)          #append bias with all ones at the end of dataset\n",
        "x_train = np.append(np.ones((x_train.shape[0],1)), x_train, axis=1)\n",
        "\n",
        "#Initialize parameters\n",
        "alpha=1\n",
        "num_iters = 100\n",
        "batch_size = 1\n",
        "params = np.zeros((num_of_features+1,1))\n",
        "\n",
        "#train the model by batch gradient descent\n",
        "params, cost = logistic_regression_using_batch_gradient_descent(x_train, y_train_reshaped, params, alpha, num_iters, batch_size)\n",
        "\n",
        "#test the model, get prediction\n",
        "y_predict = Predict(params, x_test)\n",
        "#print(\"prediction\", y_predict.transpose())\n",
        "#print(\"y_test\", y_test.to_numpy())\n",
        "\n",
        "#compute accuracy of the model\n",
        "print(\"\\nLogistic Regression - Raw\")\n",
        "evaluate(y_test, y_predict)\n",
        "print(\"\\nTo compare with sklearn classification_report\")\n",
        "print(\"--------------------------------------------\")\n",
        "print(classification_report(y_test, y_predict))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpxZr2bpxVVx",
        "outputId": "b381e4fe-dc4d-4876-cddb-2b5c54e22d21"
      },
      "execution_count": 1207,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: overflow encountered in exp\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Logistic Regression - Raw\n",
            "\n",
            "Confusion Matrix\n",
            "----------------------------------------------------\n",
            "\t\t\tPredicted\n",
            "Actual           Negative  Positive\n",
            "Negative       289       482\n",
            "Positive        78       147 \n",
            "\n",
            "matches: 436 total number of samples: 996\n",
            "\n",
            "Logistic Regression Performance\n",
            "---------------------------------------------------\n",
            " accuracy  precision   recall  total number of samples\n",
            " 0.437751   0.233704 0.653333                      996 \n",
            "\n",
            "\n",
            "To compare with sklearn classification_report\n",
            "--------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.37      0.51       771\n",
            "           1       0.23      0.65      0.34       225\n",
            "\n",
            "    accuracy                           0.44       996\n",
            "   macro avg       0.51      0.51      0.43       996\n",
            "weighted avg       0.66      0.44      0.47       996\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predict by perceptron regression - raw data\n",
        "\n",
        "#Initialize parameters\n",
        "alpha=0.1\n",
        "num_iters = 200\n",
        "batch_size = 1\n",
        "params = np.zeros((num_of_features+1,1))\n",
        "\n",
        "y_prediction = []\n",
        "\n",
        "#train the model \n",
        "perceptron1 = Perceptron(num_of_features, alpha)\n",
        "perceptron1.fit(x_train, y_train, epochs = num_iters)\n",
        "\n",
        "#test the model\n",
        "for (x, target) in zip(x_test, y_test):\n",
        "  pred = perceptron1.predict(x)\n",
        "  y_prediction.append(pred)\n",
        "#print(\"y_prediction\",  y_prediction)\n",
        "\n",
        "#compute accuracy of the model\n",
        "print(\"\\nPerceptron Regression - Raw\")\n",
        "evaluate(y_test, np.array(y_prediction))\n",
        "print(\"\\nTo compare with sklearn classification_report\")\n",
        "print(\"--------------------------------------------\")\n",
        "print(classification_report(y_test, y_prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcRz3cVj6gnl",
        "outputId": "5fdbe8cb-044c-4d91-97a4-d3337391df85"
      },
      "execution_count": 1208,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Perceptron Regression - Raw\n",
            "\n",
            "Confusion Matrix\n",
            "----------------------------------------------------\n",
            "\t\t\tPredicted\n",
            "Actual           Negative  Positive\n",
            "Negative       498       273\n",
            "Positive       142        83 \n",
            "\n",
            "matches: 581 total number of samples: 996\n",
            "\n",
            "Logistic Regression Performance\n",
            "---------------------------------------------------\n",
            " accuracy  precision   recall  total number of samples\n",
            " 0.583333   0.233146 0.368889                      996 \n",
            "\n",
            "\n",
            "To compare with sklearn classification_report\n",
            "--------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.65      0.71       771\n",
            "           1       0.23      0.37      0.29       225\n",
            "\n",
            "    accuracy                           0.58       996\n",
            "   macro avg       0.51      0.51      0.50       996\n",
            "weighted avg       0.66      0.58      0.61       996\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predict by perceptron regression - normalized data\n",
        "\n",
        "#Initialize parameters\n",
        "alpha = 1\n",
        "num_iters = 100\n",
        "batch_size = 1\n",
        "params = np.zeros((num_of_features+1,1))\n",
        "\n",
        "y_normalized_prediction = []\n",
        "\n",
        "#train the model \n",
        "perceptron2 = Perceptron(num_of_features, alpha)\n",
        "perceptron2.fit(x_train_minmax_normalized, y_train, epochs = num_iters)\n",
        "\n",
        "#test the model\n",
        "for (x, target) in zip(x_test_minmax_normalized, y_test):\n",
        "  pred = perceptron2.predict(x)\n",
        "  y_normalized_prediction.append(pred)\n",
        "#print(\"y_normalized_prediction\",  y_normalized_prediction)\n",
        "\n",
        "#compute accuracy of the model\n",
        "print(\"\\nPerceptron Regression - MinMax Normalized\")\n",
        "evaluate(y_test, np.array(y_normalized_prediction))\n",
        "print(\"\\nTo compare with sklearn classification_report\")\n",
        "print(\"------------------------------------------\")\n",
        "print(classification_report(y_test, y_normalized_prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqfLMPgeHcGP",
        "outputId": "1581a0ab-f401-4ad1-a337-b02e57093932"
      },
      "execution_count": 1209,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Perceptron Regression - MinMax Normalized\n",
            "\n",
            "Confusion Matrix\n",
            "----------------------------------------------------\n",
            "\t\t\tPredicted\n",
            "Actual           Negative  Positive\n",
            "Negative       725        46\n",
            "Positive       155        70 \n",
            "\n",
            "matches: 795 total number of samples: 996\n",
            "\n",
            "Logistic Regression Performance\n",
            "---------------------------------------------------\n",
            " accuracy  precision   recall  total number of samples\n",
            " 0.798193   0.603448 0.311111                      996 \n",
            "\n",
            "\n",
            "To compare with sklearn classification_report\n",
            "------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.94      0.88       771\n",
            "           1       0.60      0.31      0.41       225\n",
            "\n",
            "    accuracy                           0.80       996\n",
            "   macro avg       0.71      0.63      0.64       996\n",
            "weighted avg       0.77      0.80      0.77       996\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To compare the result of training and testing results of the 4 models, they all run learning rate = 1 and epochs = 100.  I have tried other values of hyper parameters, but the abovesaid values return the most stable result.  I have also tried to run a set of the 4 models - logistic regression with normalized data, but by using the default settings, it returns even worse result (accuracy ~55%, v/s my model ~77%)\n",
        "\n",
        "Normalized dataset gives much higher accuracy.  From the above results, i observe 77% accuracy for logistic regression, and 80% for perceptron regression.  On the other hand, raw dataset can only produce 44% accuracy by logistics and 60% by perceptron.\n",
        "\n",
        "The difference happens when features of a dataset have different ranges.  Result is influenced by larger values.\n",
        "\n",
        "The results also show the accuracy, precision, recall of perceptron regression is slightly better than logistics.  However, both regressions are binary classifiers, the threshould to put a prediction into 1 or 0 may be different, logistics regression additionally brings the benefit of resulting a probability, but in all, in terms of accuracy, both regressions should not show a significant difference."
      ],
      "metadata": {
        "id": "nemQEKckhA3O"
      }
    }
  ]
}
