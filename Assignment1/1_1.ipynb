{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1.1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ZSVS6rczYdSYi11IxinLuXV2dSKys4-l",
      "authorship_tag": "ABX9TyPXSs+2ozKjyg6DriLSRyVS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cakwok/CS6140-Machine-Learning/blob/main/1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CS6140 Assignment 1 Q1.1\n",
        "Wing Man, Kwok  \n",
        "05/18/2022"
      ],
      "metadata": {
        "id": "Wy5oorqrDuOI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "6H1blSxuZRLN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split  #Split training and testing data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassificationDecisionTree:                       #Build Classification Decision Tree for dataset data.csv\n",
        "    def __init__(self, max_depth=10, min_samples=2):    #initialize object paramenters\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples = min_samples\n",
        "        self.root = None\n",
        "\n",
        "    def terminate(self, depth):                         #check if termination criteria is met\n",
        "        if (depth >= self.max_depth or self.numofClasslabels == 1 or self.numofSamples < self.min_samples):\n",
        "            return True\n",
        "        return False\n",
        "           \n",
        "    def fit(self, X, y):                                #fit dataset into the tree    \n",
        "        self.root = self.build_tree(X, y)\n",
        "\n",
        "    def compute_entropy(self, y):                       #compute root/parent node entropy\n",
        "        entropy = 0\n",
        "        bin_propability = np.bincount(y) / len(y)       #count occurence of a value which matches with index, then normalize\n",
        "        for p in bin_propability:\n",
        "          if p > 0:\n",
        "            entropy += -p * np.log2(p)\n",
        "        return entropy\n",
        "\n",
        "    def split_datapoints_to_leftright(self, X, best_information_gain_X):\n",
        "        left_index = np.argwhere(X <= best_information_gain_X).flatten()     #split data points to left if smaller than variable X of best information gain\n",
        "        right_index = np.argwhere(X > best_information_gain_X).flatten()     #split data points to right if larger than variable X of best information gain\n",
        "        return left_index, right_index                                       #return location(index) of the data point split into left and right correspondingly\n",
        "\n",
        "    def compute_information_gain(self, X, y, best_information_gain_X):        #compute information gain of a branch\n",
        "        parent_loss = self.compute_entropy(y)\n",
        "        left_index, right_index = self.split_datapoints_to_leftright(X, best_information_gain_X)\n",
        "        \n",
        "        if len(left_index) == 0 or len(right_index) == 0: \n",
        "            return 0\n",
        "        \n",
        "        child_loss = (len(left_index) / len(y)) * self.compute_entropy(y[left_index]) + (len(right_index) / len(y)) * self.compute_entropy(y[right_index])\n",
        "        return parent_loss - child_loss\n",
        "\n",
        "    def find_max_information_gain(self, X, y, features):                      #find max information gain for each datapoint\n",
        "      \n",
        "        axis_aligned_rectangle_score = - 1\n",
        "        axis_aligned_rectangle_feature = None\n",
        "        axis_aligned_rectangle_iris_dimension = None\n",
        "\n",
        "        for feat in features:                           #for each feature, source, eg, [3 1 2 0]\n",
        "  \n",
        "            X_feat = X[:, feat]                         #extract one column of X.  Format: X[row_index, column_index]\n",
        "            iris_dimensions = np.unique(X_feat)         #returns the sorted unique elements of the X column.  each represents a data point of X column\n",
        "   \n",
        "            for iris_dimension in iris_dimensions:      #for each unique datapoint of iris species measurement\n",
        "                score = self.compute_information_gain(X_feat, y, iris_dimension) #calculate information gain\n",
        "                if score > axis_aligned_rectangle_score:\n",
        "                    axis_aligned_rectangle_score = score\n",
        "                    axis_aligned_rectangle_feature = feat\n",
        "                    axis_aligned_rectangle_iris_dimension = iris_dimension\n",
        "\n",
        "        return axis_aligned_rectangle_feature, axis_aligned_rectangle_iris_dimension\n",
        "    \n",
        "    def build_tree(self, X, y, depth=0):\n",
        "\n",
        "        self.numofSamples, self.numofFeatures = X.shape   #X.shape = 105, 4 (105 training dataset, 4 features)\n",
        "        self.numofClasslabels = len(np.unique(y))         #return number of unique labels of column y (label)\n",
        "\n",
        "        #exit criteria\n",
        "        if self.terminate(depth):                         \n",
        "            predicted_label = np.argmax(np.bincount(y))   #return the max of count of elements value same as array index\n",
        "            return Node(value=predicted_label)\n",
        "\n",
        "        #iterate each data point, find the data point with maxiumn information gain\n",
        "        random_features = np.random.choice(self.numofFeatures, self.numofFeatures, replace=False) #generate 4 numbers, range 0 to 4, eg [0 1 2 3], [3 2 0 1]\n",
        "        best_feature, best_information_gain = self.find_max_information_gain(X, y, random_features) #locate the datapoint with best information gain\n",
        "\n",
        "        # populate children \n",
        "        left_index, right_index = self.split_datapoints_to_leftright(X[:, best_feature], best_information_gain)\n",
        "        left_child = self.build_tree(X[left_index, :], y[left_index], depth + 1)\n",
        "        right_child = self.build_tree(X[right_index, :], y[right_index], depth + 1)\n",
        "        return Node(best_feature, best_information_gain, left_child, right_child)\n",
        "\n",
        "    def traverse_tree(self, x, node):\n",
        "        if node.is_leaf():\n",
        "            return node.value\n",
        "    \n",
        "        if x[node.feature] <= node.threshold:                   #follow the logic of building tree, so now look up the x variables of the node feature and compare the value with best information gain\n",
        "            return self.traverse_tree(x, node.left)\n",
        "        \n",
        "        return self.traverse_tree(x, node.right)\n",
        "        \n",
        "    def print_tree(self, node):                                 #print tree by pre-order traversal (root left first)\n",
        "      if node.is_leaf():\n",
        "          print (\"node\", node)\n",
        "          print (\"Class\", node.value)\n",
        "          return node.value\n",
        "      \n",
        "      print (\"node\", node) \n",
        "      print (\"feature\", node.feature, \"<=\", node.threshold )\n",
        "      print (\"node.left\", node.left)\n",
        "      print (\"node.right\", node.right)\n",
        "      print (\"\\n\")\n",
        "      \n",
        "      print (\"left \", end='')\n",
        "      self.print_tree(node.left)\n",
        "\n",
        "      print (\"right \", end='')\n",
        "      self.print_tree(node.right)\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = []\n",
        "        for x in X:                                                     #x represent each row of X\n",
        "          predictions.append(self.traverse_tree(x, self.root))\n",
        "        return np.array(predictions)\n",
        "        "
      ],
      "metadata": {
        "id": "ikGaa9tS1hBk"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "    def __init__(self, feature=None, threshold=None, left=None, right=None, *, value=None):\n",
        "        self.feature = feature\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.value = value\n",
        "    \n",
        "    def is_leaf(self):\n",
        "        return self.value is not None"
      ],
      "metadata": {
        "id": "j2L4hHnh1pLQ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "UJyPsmFB1XAr"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/CS6140 Assignment1/data.csv\")\n"
      ],
      "metadata": {
        "id": "mXHvM-fy39um"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_cols = ['feature1', 'feature2', 'feature3', 'feature4']\n",
        "X = dataset[feature_cols]                         #Assign all feature columns into variable X\n",
        "y = dataset['class']                              #Assign all target columns into variable y\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=1\n",
        ")\n",
        "\n",
        "model = ClassificationDecisionTree(max_depth=10)\n",
        "model.fit(X_train.values , y_train.values)"
      ],
      "metadata": {
        "id": "DDvvb2VT4jY7"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"X_test\", X_test)\n",
        "y_pred = model.predict(X_test.values)\n",
        "print (\"y_pred\", y_pred)\n",
        "acc = accuracy(y_test, y_pred)\n",
        "print(\"Accuracy:\", acc)"
      ],
      "metadata": {
        "id": "U3Y1dF5kGxfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.print_tree(model.root)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFk05_asfEpb",
        "outputId": "4db95a8c-fd19-4d3c-9b25-4c7626e75917"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "node <__main__.Node object at 0x7f02abc94490>\n",
            "feature 3 <= 0.6\n",
            "node.left <__main__.Node object at 0x7f02abc94690>\n",
            "node.right <__main__.Node object at 0x7f02abc94a10>\n",
            "\n",
            "\n",
            "left node <__main__.Node object at 0x7f02abc94690>\n",
            "Class 0\n",
            "right node <__main__.Node object at 0x7f02abc94a10>\n",
            "feature 3 <= 1.6\n",
            "node.left <__main__.Node object at 0x7f02abc94650>\n",
            "node.right <__main__.Node object at 0x7f02abc94510>\n",
            "\n",
            "\n",
            "left node <__main__.Node object at 0x7f02abc94650>\n",
            "feature 2 <= 4.9\n",
            "node.left <__main__.Node object at 0x7f02abc94290>\n",
            "node.right <__main__.Node object at 0x7f02abc94610>\n",
            "\n",
            "\n",
            "left node <__main__.Node object at 0x7f02abc94290>\n",
            "Class 1\n",
            "right node <__main__.Node object at 0x7f02abc94610>\n",
            "feature 3 <= 1.5\n",
            "node.left <__main__.Node object at 0x7f02abc94ed0>\n",
            "node.right <__main__.Node object at 0x7f02abc94990>\n",
            "\n",
            "\n",
            "left node <__main__.Node object at 0x7f02abc94ed0>\n",
            "Class 2\n",
            "right node <__main__.Node object at 0x7f02abc94990>\n",
            "Class 1\n",
            "right node <__main__.Node object at 0x7f02abc94510>\n",
            "Class 2\n"
          ]
        }
      ]
    }
  ]
}
